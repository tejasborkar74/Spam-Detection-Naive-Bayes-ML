{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('D:\\\\5th sem\\\\ML\\\\Projects\\\\Dataset\\\\SMSSpamCollection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Convert f1 into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Data Frame\n",
    "\n",
    "\n",
    "#Make df for raw data\n",
    "arr = np.empty((0,2)) \n",
    "for line in f1:\n",
    "    l = len(line)-1\n",
    "    if line[0] == 'h':\n",
    "        text1 = 0\n",
    "        text2 = line[4:l]\n",
    "        arr = np.append(arr, np.array([[text2 , text1]]) , axis = 0)  \n",
    "      \n",
    "    else :\n",
    "        text1 = 1\n",
    "        text2 = line[5:l]\n",
    "        arr = np.append(arr, np.array([[text2 , text1]]) , axis = 0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  email spam\n",
      "0     Go until jurong point, crazy.. Available only ...    0\n",
      "1                         Ok lar... Joking wif u oni...    0\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...    1\n",
      "3     U dun say so early hor... U c already then say...    0\n",
      "4     Nah I don't think he goes to usf, he lives aro...    0\n",
      "...                                                 ...  ...\n",
      "5569  This is the 2nd time we have tried 2 contact u...    1\n",
      "5570              Will Ã¼ b going to esplanade fr home?    0\n",
      "5571  Pity, * was in mood for that. So...any other s...    0\n",
      "5572  The guy did some bitching but I acted like i'd...    0\n",
      "5573                         Rofl. Its true to its name    0\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "col = [\"email\" , \"spam\"]\n",
    "df =  pd.DataFrame(data = arr , columns = col)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 2)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['email', 'spam'], dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "#New shape of the df\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email    0\n",
       "spam     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Missing data (NAN,na,NaN) for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download stopward package\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_email(email):\n",
    "\n",
    "    #1 remove punctuations\n",
    "    nopunct = [char for char in email if char not in string.punctuation]\n",
    "    nopunct = ''.join(nopunct)#List to string \n",
    "    \n",
    "    #2 convert into lower case\n",
    "    nopunct = nopunct.lower()\n",
    "    \n",
    "    #3 remove stopwords\n",
    "    clean_words = [word for word in nopunct.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    return clean_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  email spam\n",
      "0     Go until jurong point, crazy.. Available only ...    0\n",
      "1                         Ok lar... Joking wif u oni...    0\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...    1\n",
      "3     U dun say so early hor... U c already then say...    0\n",
      "4     Nah I don't think he goes to usf, he lives aro...    0\n",
      "...                                                 ...  ...\n",
      "5166  This is the 2nd time we have tried 2 contact u...    1\n",
      "5167              Will Ã¼ b going to esplanade fr home?    0\n",
      "5168  Pity, * was in mood for that. So...any other s...    0\n",
      "5169  The guy did some bitching but I acted like i'd...    0\n",
      "5170                         Rofl. Its true to its name    0\n",
      "\n",
      "[5171 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace = True, drop = True) \n",
    "\n",
    "df['email'].head().apply(process_email)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Vocablury of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vocab = CountVectorizer(analyzer=process_email).fit_transform(df['email'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3786)\t1\n",
      "  (0, 4696)\t1\n",
      "  (0, 6445)\t1\n",
      "  (0, 2485)\t1\n",
      "  (0, 1389)\t1\n",
      "  (0, 1860)\t1\n",
      "  (0, 5686)\t1\n",
      "  (0, 3883)\t1\n",
      "  (0, 9208)\t1\n",
      "  (0, 4858)\t1\n",
      "  (0, 3016)\t1\n",
      "  (0, 1858)\t1\n",
      "  (0, 2200)\t1\n",
      "  (0, 3843)\t1\n",
      "  (0, 1156)\t1\n",
      "  (0, 8969)\t1\n",
      "  (1, 6006)\t1\n",
      "  (1, 4897)\t1\n",
      "  (1, 4664)\t1\n",
      "  (1, 9103)\t1\n",
      "  (1, 8626)\t1\n",
      "  (1, 6038)\t1\n",
      "  (2, 3571)\t1\n",
      "  (2, 3152)\t2\n",
      "  (2, 416)\t1\n",
      "  :\t:\n",
      "  (5167, 3805)\t1\n",
      "  (5167, 9528)\t1\n",
      "  (5167, 3558)\t1\n",
      "  (5167, 3180)\t1\n",
      "  (5168, 5576)\t1\n",
      "  (5168, 6371)\t1\n",
      "  (5168, 7626)\t1\n",
      "  (5168, 8002)\t1\n",
      "  (5169, 3571)\t1\n",
      "  (5169, 4340)\t1\n",
      "  (5169, 5010)\t1\n",
      "  (5169, 9018)\t1\n",
      "  (5169, 5788)\t1\n",
      "  (5169, 8750)\t1\n",
      "  (5169, 7651)\t1\n",
      "  (5169, 3095)\t1\n",
      "  (5169, 3696)\t1\n",
      "  (5169, 1895)\t1\n",
      "  (5169, 4477)\t1\n",
      "  (5169, 3945)\t1\n",
      "  (5169, 974)\t1\n",
      "  (5169, 1643)\t1\n",
      "  (5170, 5699)\t1\n",
      "  (5170, 8556)\t1\n",
      "  (5170, 7068)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 9532)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vocab.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier :\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.X_filtered1 = self.X_train[self.y_train == 1]\n",
    "        self.X_filtered0 = self.X_train[self.y_train == 0]\n",
    "        self.sum_all1 = np.sum(self.X_filtered1[:,:])\n",
    "        self.sum_all0 = np.sum(self.X_filtered0[:,:])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    #label => spam/ham\n",
    "    def prior_prob(self, label):\n",
    "        total = self.X_train.shape[0]\n",
    "        label_total = np.sum(self.y_train == label)\n",
    "        return label_total/total\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Conditional probability P(Xi/label)\n",
    "    def conditional_prob(self, col_name, col_value, label):\n",
    "        if label == 1 :\n",
    "            X_filtered = self.X_filtered1\n",
    "            numerator = np.sum(X_filtered[:, col_name]) + 1\n",
    "            denominator = self.sum_all1 + self.X_train.shape[1]\n",
    "        else:\n",
    "            X_filtered = self.X_filtered0\n",
    "            numerator = np.sum(X_filtered[:, col_name]) + 1\n",
    "            denominator = self.sum_all0 + self.X_train.shape[1]\n",
    "        \n",
    "        return float(float(numerator)/float(denominator))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        row = X_test.shape[0]\n",
    "        col = X_test.shape[1]\n",
    "        pp1 = self.prior_prob(1)\n",
    "        pp0 = self.prior_prob(0)\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        for i in range(row):\n",
    "            s_prob =1.0\n",
    "            ns_prob =1.0\n",
    "            #print(i,end=\" \")\n",
    "            \n",
    "            for j in range(col):\n",
    "                if X_test[i][j] > 0:\n",
    "                    s_prob = s_prob*self.conditional_prob(j , X_test[i][j],1);\n",
    "                    ns_prob =ns_prob*self.conditional_prob(j , X_test[i][j],0);\n",
    "                \n",
    "            s_prob= s_prob*pp1\n",
    "            ns_prob = ns_prob*pp0\n",
    "            #print(s_prob , ns_prob)\n",
    "            if s_prob>ns_prob :\n",
    "                pred.append(1)\n",
    "            else :\n",
    "                pred.append(0)\n",
    "        return pred;\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def confusion_mat(Y_test, pred):\n",
    "    #TN=0,TP=0,FN=0,FP=0\n",
    "    TN = 0\n",
    "    TP=0\n",
    "    FN=0\n",
    "    FP=0\n",
    "    \n",
    "\n",
    "    for i in range(len(Y_test)):\n",
    "        \n",
    "        if pred[i] == 0 and Y_test[i] == 0:\n",
    "            TN=TN+1\n",
    "        elif pred[i] == 1 and Y_test[i] == 1:\n",
    "            TP=TP+1\n",
    "        elif pred[i] == 1 and Y_test[i] == 0:\n",
    "            FP=FP+1\n",
    "        else:\n",
    "            FN=FN+1\n",
    "    \n",
    "    return TN,TP,FN,FP\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(TN,TP,FN,FP):\n",
    "    total = TN+TP+FN+FP\n",
    "    return (TN+TP)/total\n",
    "\n",
    "\n",
    "def precision_score(TN,TP,FN,FP):\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "\n",
    "def recall_score(TN,TP,FN,FP):\n",
    "    return TP/(TP+FN)\n",
    "\n",
    "\n",
    "def f0pt5_score(TN,TP,FN,FP):\n",
    "    p = TP/(TP+FP)\n",
    "    r = TP/(TP+FN)\n",
    "    return  5*p*r/(p+r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting in 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(vocab, df['spam'], test_size=0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.toarray()\n",
    "X_train = X_train.toarray()\n",
    "\n",
    "Y_test = np.array([int(i) for i in Y_test])\n",
    "Y_train = np.array([int(i) for i in Y_train])\n",
    "\n",
    "# Y_test = Y_test.reset_index()\n",
    "# Y_train = Y_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1035, 9532)\n",
      "(1035,)\n",
      "(4136, 9532)\n",
      "(4136,)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "------------------------------------------\n",
      "[1 0 0 ... 0 1 1]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))\n",
    "print(type(X_train))\n",
    "print(type(Y_test))\n",
    "print(type(Y_train))\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test)\n",
    "print('------------------------------------------')\n",
    "print(Y_train)\n",
    "print(Y_test)\n",
    "# print(X_train)\n",
    "#print(type(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier()\n",
    "classifier.fit(X_train , Y_train)\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "\n",
    "print(pred)\n",
    "type(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Performance Measures for Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN  872\n",
      "FP  28\n",
      "FN  11\n",
      "TP  124\n"
     ]
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "\n",
    "TN,TP,FN,FP = confusion_mat(Y_test,pred)\n",
    "\n",
    "print(\"TN \", TN)\n",
    "print(\"FP \", FP)\n",
    "print(\"FN \", FN)\n",
    "print(\"TP \", TP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY   :  0.9623188405797102\n",
      "PRECISION  :  0.8157894736842105\n",
      "RECALL     :  0.9185185185185185\n",
      "F0.5_SCORE :  2.160278745644599\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY   : \",accuracy_score(TN,TP,FN,FP))\n",
    "print(\"PRECISION  : \",precision_score(TN,TP,FN,FP))\n",
    "print(\"RECALL     : \",recall_score(TN,TP,FN,FP))\n",
    "print(\"F0.5_SCORE : \",f0pt5_score(TN,TP,FN,FP))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=vocab\n",
    "Y=df['spam'].values\n",
    "\n",
    "Y = np.array([int(i) for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN  443  TP  63  FN  3  FP  9\n",
      "TN  440  TP  62  FN  3  FP  12\n",
      "TN  444  TP  61  FN  4  FP  8\n",
      "TN  446  TP  59  FN  6  FP  6\n",
      "TN  443  TP  60  FN  5  FP  9\n",
      "TN  445  TP  57  FN  8  FP  7\n",
      "TN  440  TP  60  FN  5  FP  12\n",
      "TN  443  TP  59  FN  6  FP  9\n",
      "TN  435  TP  60  FN  6  FP  16\n",
      "TN  444  TP  64  FN  2  FP  7\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f0pt5 = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits =10, random_state = None)\n",
    "skf.get_n_splits(X ,Y)\n",
    "\n",
    "for train_index, test_index in skf.split(vocab , df['spam'].values):\n",
    "   # print(\"Train:\", train_index , \"Validation:\", test_index)\n",
    "    \n",
    "    X1_train , X1_test = X[train_index], X[test_index]\n",
    "    y1_train , y1_test = Y[train_index], Y[test_index]\n",
    "    \n",
    " \n",
    "    X1_test=X1_test.toarray()\n",
    "    X1_train = X1_train.toarray()\n",
    "    \n",
    "    classifier.fit(X1_train,y1_train)\n",
    "    prediction = classifier.predict(X1_test)\n",
    "    \n",
    "    TN,TP,FN,FP = confusion_mat(y1_test,prediction)\n",
    "    \n",
    "    print(\"TN \", TN , \" TP \" , TP , \" FN \" , FN , \" FP \", FP)  \n",
    "\n",
    "    accuracy.append(accuracy_score(TN,TP,FN,FP))\n",
    "  \n",
    "    precision.append(precision_score(TN,TP,FN,FP))\n",
    "\n",
    "    recall.append(recall_score(TN,TP,FN,FP))\n",
    "\n",
    "    f0pt5.append(f0pt5_score(TN,TP,FN,FP))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures of Stratified K fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACIES  :  [0.9768339768339769, 0.9709864603481625, 0.97678916827853, 0.97678916827853, 0.9729206963249516, 0.9709864603481625, 0.9671179883945842, 0.9709864603481625, 0.9574468085106383, 0.9825918762088974]\n",
      "PRECISIONS  :  [0.875, 0.8378378378378378, 0.8840579710144928, 0.9076923076923077, 0.8695652173913043, 0.890625, 0.8333333333333334, 0.8676470588235294, 0.7894736842105263, 0.9014084507042254]\n",
      "RECALL      :  [0.9545454545454546, 0.9538461538461539, 0.9384615384615385, 0.9076923076923077, 0.9230769230769231, 0.8769230769230769, 0.9230769230769231, 0.9076923076923077, 0.9090909090909091, 0.9696969696969697]\n",
      "F0.5_SCORE  :  [2.2826086956521743, 2.23021582733813, 2.2761194029850746, 2.269230769230769, 2.2388059701492535, 2.2093023255813953, 2.1897810218978107, 2.218045112781955, 2.1126760563380285, 2.335766423357664]\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACIES  : \",accuracy)\n",
    "print(\"PRECISIONS  : \",precision)\n",
    "print(\"RECALL      : \",recall)\n",
    "print(\"F0.5_SCORE  : \",f0pt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY    :  0.9723449063874596\n",
      "PRECISION   :  0.8656640861007557\n",
      "RECALL      :  0.9264102564102564\n",
      "F0.5_SCORE  :  2.2362551605312255\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean \n",
    "\n",
    "print(\"ACCURACY    : \",mean(accuracy))\n",
    "print(\"PRECISION   : \",mean(precision))\n",
    "print(\"RECALL      : \",mean(recall))\n",
    "print(\"F0.5_SCORE  : \",mean(f0pt5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
