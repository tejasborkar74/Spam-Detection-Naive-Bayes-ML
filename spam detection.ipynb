{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open('D:\\\\5th sem\\\\ML\\\\Projects\\\\Dataset\\\\SMSSpamCollection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Convert f1 into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Data Frame\n",
    "\n",
    "\n",
    "#Make df for raw data\n",
    "arr = np.empty((0,2)) \n",
    "for line in f1:\n",
    "    l = len(line)-1\n",
    "    if line[0] == 'h':\n",
    "        text1 = 0\n",
    "        text2 = line[4:l]\n",
    "        arr = np.append(arr, np.array([[text2 , text1]]) , axis = 0)  \n",
    "      \n",
    "    else :\n",
    "        text1 = 1\n",
    "        text2 = line[5:l]\n",
    "        arr = np.append(arr, np.array([[text2 , text1]]) , axis = 0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  email spam\n",
      "0     Go until jurong point, crazy.. Available only ...    0\n",
      "1                         Ok lar... Joking wif u oni...    0\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...    1\n",
      "3     U dun say so early hor... U c already then say...    0\n",
      "4     Nah I don't think he goes to usf, he lives aro...    0\n",
      "...                                                 ...  ...\n",
      "5569  This is the 2nd time we have tried 2 contact u...    1\n",
      "5570              Will Ã¼ b going to esplanade fr home?    0\n",
      "5571  Pity, * was in mood for that. So...any other s...    0\n",
      "5572  The guy did some bitching but I acted like i'd...    0\n",
      "5573                         Rofl. Its true to its name    0\n",
      "\n",
      "[5574 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "col = [\"email\" , \"spam\"]\n",
    "df =  pd.DataFrame(data = arr , columns = col)\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['email', 'spam'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "#New shape of the df\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email    0\n",
       "spam     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Missing data (NAN,na,NaN) for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download stopward package\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_email(email):\n",
    "\n",
    "    #1 remove punctuations\n",
    "    nopunct = [char for char in email if char not in string.punctuation]\n",
    "    nopunct = ''.join(nopunct)#List to string \n",
    "    \n",
    "    #2 convert into lower case\n",
    "    nopunct = nopunct.lower()\n",
    "    \n",
    "    #3 remove stopwords\n",
    "    clean_words = [word for word in nopunct.split() if word not in stopwords.words('english')]\n",
    "    \n",
    "    return clean_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  email spam\n",
      "0     Go until jurong point, crazy.. Available only ...    0\n",
      "1                         Ok lar... Joking wif u oni...    0\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...    1\n",
      "3     U dun say so early hor... U c already then say...    0\n",
      "4     Nah I don't think he goes to usf, he lives aro...    0\n",
      "...                                                 ...  ...\n",
      "5166  This is the 2nd time we have tried 2 contact u...    1\n",
      "5167              Will Ã¼ b going to esplanade fr home?    0\n",
      "5168  Pity, * was in mood for that. So...any other s...    0\n",
      "5169  The guy did some bitching but I acted like i'd...    0\n",
      "5170                         Rofl. Its true to its name    0\n",
      "\n",
      "[5171 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(inplace = True, drop = True) \n",
    "\n",
    "df['email'].head().apply(process_email)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Vocablury of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vocab = CountVectorizer(analyzer=process_email).fit_transform(df['email'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3786)\t1\n",
      "  (0, 4696)\t1\n",
      "  (0, 6445)\t1\n",
      "  (0, 2485)\t1\n",
      "  (0, 1389)\t1\n",
      "  (0, 1860)\t1\n",
      "  (0, 5686)\t1\n",
      "  (0, 3883)\t1\n",
      "  (0, 9208)\t1\n",
      "  (0, 4858)\t1\n",
      "  (0, 3016)\t1\n",
      "  (0, 1858)\t1\n",
      "  (0, 2200)\t1\n",
      "  (0, 3843)\t1\n",
      "  (0, 1156)\t1\n",
      "  (0, 8969)\t1\n",
      "  (1, 6006)\t1\n",
      "  (1, 4897)\t1\n",
      "  (1, 4664)\t1\n",
      "  (1, 9103)\t1\n",
      "  (1, 8626)\t1\n",
      "  (1, 6038)\t1\n",
      "  (2, 3571)\t1\n",
      "  (2, 3152)\t2\n",
      "  (2, 416)\t1\n",
      "  :\t:\n",
      "  (5167, 3805)\t1\n",
      "  (5167, 9528)\t1\n",
      "  (5167, 3558)\t1\n",
      "  (5167, 3180)\t1\n",
      "  (5168, 5576)\t1\n",
      "  (5168, 6371)\t1\n",
      "  (5168, 7626)\t1\n",
      "  (5168, 8002)\t1\n",
      "  (5169, 3571)\t1\n",
      "  (5169, 4340)\t1\n",
      "  (5169, 5010)\t1\n",
      "  (5169, 9018)\t1\n",
      "  (5169, 5788)\t1\n",
      "  (5169, 8750)\t1\n",
      "  (5169, 7651)\t1\n",
      "  (5169, 3095)\t1\n",
      "  (5169, 3696)\t1\n",
      "  (5169, 1895)\t1\n",
      "  (5169, 4477)\t1\n",
      "  (5169, 3945)\t1\n",
      "  (5169, 974)\t1\n",
      "  (5169, 1643)\t1\n",
      "  (5170, 5699)\t1\n",
      "  (5170, 8556)\t1\n",
      "  (5170, 7068)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 9532)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(vocab.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier :\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.X_filtered1 = self.X_train[self.y_train == 1]\n",
    "        self.X_filtered0 = self.X_train[self.y_train == 0]\n",
    "        self.sum_all1 = np.sum(self.X_filtered1[:,:])\n",
    "        self.sum_all0 = np.sum(self.X_filtered0[:,:])\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    #label => spam/ham\n",
    "    def prior_prob(self, label):\n",
    "        total = self.X_train.shape[0]\n",
    "        label_total = np.sum(self.y_train == label)\n",
    "        return label_total/total\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Conditional probability P(Xi/label)\n",
    "    def conditional_prob(self, col_name, col_value, label):\n",
    "        if label == 1 :\n",
    "            X_filtered = self.X_filtered1\n",
    "            numerator = np.sum(X_filtered[:, col_name]) + 1\n",
    "            denominator = self.sum_all1 + self.X_train.shape[1]\n",
    "        else:\n",
    "            X_filtered = self.X_filtered0\n",
    "            numerator = np.sum(X_filtered[:, col_name]) + 1\n",
    "            denominator = self.sum_all0 + self.X_train.shape[1]\n",
    "        \n",
    "        return float(float(numerator)/float(denominator))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        row = X_test.shape[0]\n",
    "        col = X_test.shape[1]\n",
    "        pp1 = self.prior_prob(1)\n",
    "        pp0 = self.prior_prob(0)\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        for i in range(row):\n",
    "            s_prob =1.0\n",
    "            ns_prob =1.0\n",
    "            #print(i,end=\" \")\n",
    "            \n",
    "            for j in range(col):\n",
    "                if X_test[i][j] > 0:\n",
    "                    s_prob = s_prob*self.conditional_prob(j , X_test[i][j],1);\n",
    "                    ns_prob =ns_prob*self.conditional_prob(j , X_test[i][j],0);\n",
    "                \n",
    "            s_prob= s_prob*pp1\n",
    "            ns_prob = ns_prob*pp0\n",
    "            #print(s_prob , ns_prob)\n",
    "            if s_prob>ns_prob :\n",
    "                pred.append(1)\n",
    "            else :\n",
    "                pred.append(0)\n",
    "        return pred;\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting in 80% training and 20% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(vocab, df['spam'], test_size=0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.toarray()\n",
    "X_train = X_train.toarray()\n",
    "\n",
    "Y_test = np.array([int(i) for i in Y_test])\n",
    "Y_train = np.array([int(i) for i in Y_train])\n",
    "\n",
    "# Y_test = Y_test.reset_index()\n",
    "# Y_train = Y_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1035, 9532)\n",
      "(1035,)\n",
      "(4136, 9532)\n",
      "(4136,)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "------------------------------------------\n",
      "[1 0 0 ... 0 1 1]\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))\n",
    "print(type(X_train))\n",
    "print(type(Y_test))\n",
    "print(type(Y_train))\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test)\n",
    "print('------------------------------------------')\n",
    "print(Y_train)\n",
    "print(Y_test)\n",
    "# print(X_train)\n",
    "#print(type(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier()\n",
    "classifier.fit(X_train , Y_train)\n",
    "\n",
    "pred = classifier.predict(X_test)\n",
    "\n",
    "print(pred)\n",
    "type(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Performance Measures for Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[872,  28],\n",
       "       [ 11, 124]], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY   :  0.9623188405797102\n",
      "PRECISION  :  0.8157894736842105\n",
      "RECALL     :  0.9185185185185185\n",
      "F1_SCORE   :  0.8641114982578396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print(\"ACCURACY   : \",accuracy_score(Y_test,pred))\n",
    "print(\"PRECISION  : \",precision_score(Y_test,pred))\n",
    "print(\"RECALL     : \",recall_score(Y_test,pred))\n",
    "print(\"F1_SCORE   : \",f1_score(Y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=vocab\n",
    "Y=df['spam'].values\n",
    "\n",
    "Y = np.array([int(i) for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4653, 9532) (518, 9532) (4653,) (518,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n",
      "(4654, 9532) (517, 9532) (4654,) (517,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "F1_score = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits =10, random_state = None)\n",
    "skf.get_n_splits(X ,Y)\n",
    "\n",
    "for train_index, test_index in skf.split(vocab , df['spam'].values):\n",
    "   # print(\"Train:\", train_index , \"Validation:\", test_index)\n",
    "    \n",
    "    X1_train , X1_test = X[train_index], X[test_index]\n",
    "    y1_train , y1_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    print(X1_train.shape , X1_test.shape , y1_train.shape , y1_test.shape)\n",
    "    \n",
    "    X1_test=X1_test.toarray()\n",
    "    X1_train = X1_train.toarray()\n",
    "    \n",
    "    classifier.fit(X1_train,y1_train)\n",
    "    prediction = classifier.predict(X1_test)\n",
    "    \n",
    "    score = accuracy_score(y1_test,prediction)\n",
    "    accuracy.append(score)\n",
    "    score = precision_score(y1_test,prediction)\n",
    "    precision.append(score)\n",
    "    score = recall_score(y1_test,prediction)\n",
    "    recall.append(score)\n",
    "    score = f1_score(y1_test,prediction)\n",
    "    F1_score.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Measures of Stratified K fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACIES  :  [0.9768339768339769, 0.9709864603481625, 0.97678916827853, 0.97678916827853, 0.9729206963249516, 0.9709864603481625, 0.9671179883945842, 0.9709864603481625, 0.9574468085106383, 0.9825918762088974]\n",
      "PRECISIONS  :  [0.875, 0.8378378378378378, 0.8840579710144928, 0.9076923076923077, 0.8695652173913043, 0.890625, 0.8333333333333334, 0.8676470588235294, 0.7894736842105263, 0.9014084507042254]\n",
      "RECALL      :  [0.9545454545454546, 0.9538461538461539, 0.9384615384615385, 0.9076923076923077, 0.9230769230769231, 0.8769230769230769, 0.9230769230769231, 0.9076923076923077, 0.9090909090909091, 0.9696969696969697]\n",
      "F1_SCORE    :  [0.9130434782608695, 0.8920863309352518, 0.9104477611940298, 0.9076923076923076, 0.8955223880597014, 0.883720930232558, 0.8759124087591241, 0.887218045112782, 0.8450704225352113, 0.9343065693430657]\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACIES  : \",accuracy)\n",
    "print(\"PRECISIONS  : \",precision)\n",
    "print(\"RECALL      : \",recall)\n",
    "print(\"F1_SCORE    : \",F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY    :  0.9723449063874596\n",
      "PRECISION   :  0.8656640861007557\n",
      "RECALL      :  0.9264102564102564\n",
      "F1_SCORE    :  0.8945020642124901\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean \n",
    "\n",
    "print(\"ACCURACY    : \",mean(accuracy))\n",
    "print(\"PRECISION   : \",mean(precision))\n",
    "print(\"RECALL      : \",mean(recall))\n",
    "print(\"F1_SCORE    : \",mean(F1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
